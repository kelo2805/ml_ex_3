{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5q0E4Fj2IDc"
      },
      "source": [
        "# **Esercitazione 3 - Classificatori: Regressione Logistica e SVM**\n",
        "\n",
        "In questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n",
        "\n",
        "* **Regressione Logistica:** Un modello lineare che utilizza la funzione sigmoide per predire le probabilità delle classi.\n",
        "\n",
        "* **Support Vector Machines (SVM):** Efficace sia per problemi lineari che non lineari utilizzando il kernel trick."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJzlG6N92IDe"
      },
      "source": [
        "### **Dataset MNIST-784**\n",
        "\n",
        "Il dataset di riferimento sarà `MNIST-784`, già visto in precedenza. Il dataset contiene immagini di 10 classi (da 0 a 9). Per comodità utilizzeremo soltanto 2 classi inizialmente, per rendere la classificazione binaria. Nello specifico utilizzeremo soltanto le immagini che hanno come etichetta `3` e `8`.\n",
        "\n",
        "Il codice seguente esegui l' import delle librerie necessarie e la selezione delle etichette che ci interessano. Le etichette vengono anche rimpiazzate con `1` e `0`, emulando il caso di classificazione binaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIyzBfOF2IDe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "NyTBSNrm2IDf",
        "outputId": "103a415a-bd6a-4658-a5b9-a755a695fc58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenMLError",
          "evalue": "No active dataset mnist_784 found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenMLError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8e68baaabba5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 \u001b[0;34m\"both.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m             )\n\u001b[0;32m-> 1011\u001b[0;31m         data_info = _get_data_info_by_name(\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_data_info_by_name\u001b[0;34m(name, version, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SEARCH_NAME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/status/active/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No active dataset {} found.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         json_data = _get_json_content_from_openml_api(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_json_content_from_openml_api\u001b[0;34m(url, error_message, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;31m# 412 error, not in except for nicer traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mOpenMLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenMLError\u001b[0m: No active dataset mnist_784 found."
          ]
        }
      ],
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
        "X, y = mnist.data, mnist.target.astype(int)\n",
        "\n",
        "indexes = (y == 3) | (y == 8)\n",
        "X = X[indexes]\n",
        "y = y[indexes]\n",
        "\n",
        "y = np.where(y == 8, 1, 0)\n",
        "\n",
        "print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vht5D3rH2IDg"
      },
      "source": [
        "### **Divisione e standardizzazione del dataset**\n",
        "\n",
        "Dividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szJKS6cW2IDg"
      },
      "outputs": [],
      "source": [
        "# Usare le seguenti proporzioni per il train, validation e test\n",
        "train_fraction = 0.6\n",
        "validation_fraction = 0.2\n",
        "test_fraction = 0.2\n",
        "\n",
        "# svolgimento...\n",
        "dati_completi = np.c_[X, y] #concateniamo dati e target per avere un'unica matrice\n",
        "\n",
        "\n",
        "\n",
        "shape_total = dati_completi.shape[0]\n",
        "shape_train = int(shape_total * train_fraction)\n",
        "shape_val = int(shape_total * validation_fraction)\n",
        "shape_test = shape_total - shape_train - shape_val\n",
        "\n",
        "train_set = dati_completi[:shape_train]\n",
        "val_set = dati_completi[shape_train:shape_train + shape_val]\n",
        "test_set = dati_completi[shape_train + shape_val:]\n",
        "\n",
        "X_train, y_train = train_set[:, :-1], train_set[:, -1]\n",
        "X_val, y_val = val_set[:, :-1], val_set[:, -1]\n",
        "X_test, y_test = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExvwdhW92IDg"
      },
      "source": [
        "## **Esercizio 1: Implementare la Regressione Logistica**\n",
        "\n",
        "Per implementare la regressione logistica utilizzeremo la classe `sklearn.linear_model.LogisticRegression` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Per utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n",
        "\n",
        "* **`C`**: Inverso della forza di regolarizzazione L2 (λ). Valori più piccoli indicano una regolarizzazione più forte.\n",
        "* **`solver`**: Algoritmo da utilizzare nel problema di ottimizzazione (nel nostro caso, `liblinear`).\n",
        "* **`max_iter`**: Imposta il numero massimo di iterazioni affinché l'algoritmo di ottimizzazione converga e trovi i migliori parametri del modello.\n",
        "\n",
        "### Esempio di sintassi per istanziare, addestrare e predire\n",
        "\n",
        "```python\n",
        "#Importo LogisticRegression da scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#1. Instanzio il modello di Regressione Logistica\n",
        "# Durante la creazione dell' istanza imposto i parametri che desidero\n",
        "model = LogisticRegression(max_iter=100, solver='liblinear',C=1.0)\n",
        "\n",
        "#2. Train del modello utilizzando il metodo .fit()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#3. Calcolo delle predizioni utilizzando il metodo .predict()\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJVevW082IDh"
      },
      "source": [
        "### **Guida per la risoluzione**\n",
        "\n",
        "Di seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n",
        "\n",
        "1. **Creazione del modello:** Creare un' istanza della classe `LogisticRegression`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n",
        "    \n",
        "    - `max_iter` = 100\n",
        "    - `solver` = `'liblinear'`\n",
        "    - `C` = 1.0\n",
        "\n",
        "2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati.\n",
        "\n",
        "3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello.\n",
        "\n",
        "4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HvfDJWq2IDh"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Step 1 - Creazione del modello\n",
        "\n",
        "# svolgimento...\n",
        "model=LogisticRegression(max_iter=100, solver='liblinear', C=1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Nmo8O42IDh"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Addestramento del modello\n",
        "\n",
        "# svolgimento...\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSLTeK0j2IDh"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Calcolo delle predizioni\n",
        "\n",
        "# svolgimento...\n",
        "test_pred=model.predict(X_test)\n",
        "val_pred=model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqLZyYcB2IDi"
      },
      "outputs": [],
      "source": [
        "# Step 4 - Calcolo delle metriche di valutazione\n",
        "\n",
        "# svolgimento...\n",
        "correct_val=np.sum(y_val==val_pred)\n",
        "total_val=len(y_val)\n",
        "accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test=np.sum(y_test==test_pred)\n",
        "total_test=len(y_test)\n",
        "accuracy_test=correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"Validation accuracy: {accuracy_val:4f}\")\n",
        "print(f\"Test accuracy: {accuracy_test:4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Qn5GxW2IDi"
      },
      "source": [
        "## **Esercizio 2: Implementare Support Vector Machines (SVM)**\n",
        "\n",
        "Per implementare le SVM utilizziamo la classe `sklearn.svm.SVC` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
        "\n",
        "Per utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n",
        "\n",
        "* **`C`**: Parametro di regolarizzazione. L'intensità della regolarizzazione è inversamente proporzionale a C.\n",
        "* **`kernel`**: Specifica il tipo di kernel da utilizzare nell'algoritmo (`'linear'`, `'poly'`, `'rbf'`).\n",
        "\n",
        "### Esempio di sintassi per istanziare, addestrare e predire\n",
        "\n",
        "```python\n",
        "#Importare la classe SVC da scikit-learn\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#1. Creare un' istanza della classe SVC\n",
        "# Durante la creazione dell' istanza imposto i parametri che desidero\n",
        "model = SVC(kernel='linear', C=1.0)\n",
        "\n",
        "#2. Train del modello utilizzando il metodo .fit()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#3. Calcolo delle predizioni utilizzando il metodo .predict()\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfHvhUCR2IDi"
      },
      "source": [
        "### **C** in SVM:\n",
        "\n",
        "**C** è una penalità per i punti classificati erroneamente.\n",
        "\n",
        "- **Small C**: Margine più ampio, tollera alcuni errori (rischio di underfitting).\n",
        "- **Large C**: Minimizza gli errori, margine più stretto (rischio di overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt2nRZNP2IDi"
      },
      "source": [
        "### **Guida per la risoluzione**\n",
        "\n",
        "Di seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n",
        "\n",
        "1. **Creazione del modello:** Creare un' istanza della classe `SVC`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n",
        "    \n",
        "    - `kernel` = `'linear'`\n",
        "    - `C` = 0.01\n",
        "\n",
        "2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati.\n",
        "\n",
        "3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello.\n",
        "\n",
        "4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xebGOa32IDj"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Creazione del modello\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "model = SVC(kernel='linear', C=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxXsT4Xp2IDj"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Addestramento del modello\n",
        "\n",
        "# svolgimento...\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5F6Ct3p2IDj"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Calcolo delle predizioni\n",
        "\n",
        "# svolgimento...\n",
        "predictions_test = model.predict(X_test)\n",
        "predictions_val=model.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2SKZBB62IDj"
      },
      "outputs": [],
      "source": [
        "# Step 4 - Calcolo delle metriche di valutazione\n",
        "\n",
        "# svolgimento...\n",
        "correct_val=np.sum(y_val==predictions_val)\n",
        "total_val=len(y_val)\n",
        "accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test=np.sum(y_test==predictions_test)\n",
        "total_test=len(y_test)\n",
        "accuracy_test=correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"Validation accuracy: {accuracy_val:4f}\")\n",
        "print(f\"Test accuracy: {accuracy_test:4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri1ZG_y42IDj"
      },
      "source": [
        "### **Esercizio 2.1: Implementare SVM con kernel trick**\n",
        "\n",
        "Vogliamo implementare un classificatore SVM che utilizza il kernel-trick. Le linee guida sono esattamente quanto fatto prima, dobbiamo però modificare il tipo di kernel del modello. Per utilizzare il kernel trick usiamo un **kernel a base radiale (Radial Basis Function)** specificando il parametro:\n",
        "\n",
        "- `kernel` = `'rbf'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4t-Kbz92IDj"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Creazione del modello\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# svolgimento...\n",
        "model = SVC(kernel='rbf', C=0.01)\n",
        "\n",
        "# Step 2 - Addestramento del modello\n",
        "\n",
        "# svolgimento...\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3 - Calcolo delle predizioni\n",
        "\n",
        "# svolgimento...\n",
        "predictions_test = model.predict(X_test)\n",
        "predictions_val=model.predict(X_val)\n",
        "\n",
        "\n",
        "# Step 4 - Calcolo delle metriche di valutazione\n",
        "\n",
        "# svolgimento...\n",
        "correct_val=np.sum(y_val==predictions_val)\n",
        "total_val=len(y_val)\n",
        "accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test=np.sum(y_test==predictions_test)\n",
        "total_test=len(y_test)\n",
        "accuracy_test=correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"Validation accuracy: {accuracy_val:4f}\")\n",
        "print(f\"Test accuracy: {accuracy_test:4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZkjfcNI2IDk"
      },
      "source": [
        "## **Esercizio 3: Metriche di valutazione**\n",
        "\n",
        "**Matrice di confusione:**\n",
        "\n",
        "La matrice di confusione (anche nota come `confusion matrix` ) è una tabella che riassume le prestazioni di un modello di classificazione mostrando i conteggi dei veri positivi (TP), veri negativi (TN), falsi positivi (FP) e falsi negativi (FN). In questo codice, per un problema di classificazione binaria con classi 0 e 1, la `confusion matrix` è strutturata come segue:\n",
        "\n",
        "|                | **Predicted Class 0** | **Predicted Class 1** |\n",
        "|----------------|:------------------------:|:------------------------:|\n",
        "| **Actual Class 0** | TN                     | FP                     |\n",
        "| **Actual Class 1** | FN                     | TP                     |\n",
        "\n",
        "* **TN (True Negatives):** Il numero di istanze che erano effettivamente Classe 0 e sono state correttamente previste come Classe 0.\n",
        "\n",
        "* **FP (False Positives):** Il numero di istanze che erano effettivamente Classe 0 ma sono state erroneamente previste come Classe 1.\n",
        "\n",
        "* **FN (False Negatives):** Il numero di istanze che erano effettivamente Classe 1 ma sono state erroneamente previste come Classe 0.\n",
        "\n",
        "* **TP (True Positives):** Il numero di istanze che erano effettivamente Classe 1 e sono state correttamente previste come Classe 1.\n",
        "\n",
        "\n",
        "* **Accuracy:** Misura la correttezza complessiva del modello. È il rapporto tra le istanze correttamente classificate e il numero totale di istanze.\n",
        "\n",
        "    $$\n",
        "    \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "    $$\n",
        "\n",
        "* **Precision:** Misura l'accuratezza delle previsioni positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di istanze previste come positive.\n",
        "\n",
        "    $$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "* **Recall (Sensitivity or True Positive Rate):** Misura la capacità del modello di trovare tutte le istanze positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di vere istanze positive.\n",
        "\n",
        "    $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "* **F1-Score:** La media armonica di precisione e richiamo. Fornisce un punteggio unico che bilancia sia la precisione che il richiamo, particolarmente utile quando c'è una distribuzione asimmetrica delle classi.\n",
        "\n",
        "    $$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XjHbttz2IDk"
      },
      "source": [
        "Per calcolare le metriche utilizziamo le funzioni presenti in `sklearn.metrics`:\n",
        "\n",
        "#### `confusion_matrix`\n",
        "\n",
        "Dati in input il target reale e le predizioni calcola la matrice di confusione. Documentazione disponibile al seguente link [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "confusion_matrix(y_true, y_pred)\n",
        "```\n",
        "\n",
        "#### `classification_report`\n",
        "\n",
        "Genera un report testuale che mostra le principali metriche di classificazione. Documentazione disponibile al seguente link [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "classification_report(y_true, y_pred)\n",
        "```\n",
        "\n",
        "#### `precision_score`\n",
        "\n",
        "Misura il rapporto tra le istanze positive correttamente previste e il totale delle previsioni positive. Documentazione disponibile al seguente link [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html).\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "precision_score(y_true, y_pred, average='binary')\n",
        "```\n",
        "\n",
        "#### `recall_score`\n",
        "\n",
        "Misura il rapporto tra le istanze positive correttamente previste e il totale delle istanze positive effettive. Documentazione disponibile al seguente link [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "recall_score(y_true, y_pred, average='binary')\n",
        "```\n",
        "\n",
        "#### `f1_score`\n",
        "\n",
        "Calcola la media armonica di precision e recall. Documentazione disponibile al seguente link [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "f1_score(y_true, y_pred, average='binary')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv7y6B6O2IDk"
      },
      "source": [
        "### **Guida:**\n",
        "\n",
        "1. **Calcoliamo la matrice di confusione:** Calcolare la matrice di confusione con `confusion_matrix` e stamparla.\n",
        "\n",
        "2. **Calcoliamo precision, recall e F1 score:** Calcolare le metriche di valutazione con le funzioni presentate sopra e stamparle.\n",
        "\n",
        "3. **Calcoliamo il classification report:** Calcolare il classification report e stamparlo.\n",
        "\n",
        "4. **Stampare la matrice di confusione:** Utilizzare la funzione `plot_confusion_matrix` che vi abbiamo fornito per stampare la matrice di confusione. La funzione ha bisogno di un unico parametro che è la matrice di confusione calcolata al punto 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jtl-Qeyv2IDk"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Calcolare la matrice di confusione\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred_test=predictions_test\n",
        "y_pred_val=predictions_val\n",
        "\n",
        "\n",
        "# svolgimento...\n",
        "conf_matrix_test=confusion_matrix(y_test, y_pred_test) # non usiamo y_train perchè non ha senso predire i dati su cui è allenato!\n",
        "print(conf_matrix_test)\n",
        "\n",
        "conf_matrix_val=confusion_matrix(y_val, y_pred_val)\n",
        "print(conf_matrix_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECFnzmX12IDl"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Calcolare precision, recall e F1 score\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# svolgimento...\n",
        "precision_test=precision_score(y_test, y_pred_test, average='binary')\n",
        "precision_val=precision_score(y_val, y_pred_val, average='binary')\n",
        "\n",
        "recall_test=recall_score(y_test, predictions_test, average='binary')\n",
        "recall_val=recall_score(y_val, predictions_val, average='binary')\n",
        "\n",
        "f1_test=f1_score(y_test, predictions_test, average='binary')\n",
        "f1_val=f1_score(y_val, predictions_val, average='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdnRWTUf2IDl"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Calcolare il report di classificazione\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# svolgimento...\n",
        "report_test=classification_report(y_test, y_pred_test)\n",
        "print(f\"Test classification report: {report_test}\")\n",
        "\n",
        "report_val=classification_report(y_val, y_pred_val)\n",
        "print(f\"Validation classification report: {report_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnyoRJvF2IDl"
      },
      "outputs": [],
      "source": [
        "# Step 4 - Visualizzare la matrice di confusione\n",
        "\n",
        "def plot_confusion_matrix(cm):\n",
        "    \"\"\"\n",
        "    Visualizza una matrice di confusione come heatmap.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    cm : numpy.ndarray\n",
        "        La matrice di confusione da visualizzare\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# svolgimento...\n",
        "plot_confusion_matrix(conf_matrix_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2FlZLT2IDl"
      },
      "source": [
        "### **ROC Curve, AUC**\n",
        "\n",
        "Per calcolare la ROC curve, e conseguentemente l' AUC, abbiamo bisogno delle probabilità di predizione.\n",
        "\n",
        "Nel caso della **regressione logistica** possiamo utilizzare l' attributo del modello `predict_proba` da utilizzare come segue:\n",
        "\n",
        "```python\n",
        "# Estrai le probabilità della classe positiva\n",
        "y_pred_proba = classifier.predict_proba(X_test_scaled)[:, 1]\n",
        "```\n",
        "\n",
        "Per quanto riguarda invece l' **SVM**, è necessario specificare il parametro `probability` = **True** affinchè `predict_proba` funzioni.\n",
        "\n",
        "```python\n",
        "# Specifica il parametro probability=True\n",
        "classifier = SVC(kernel='linear', C=0.01, probability=True)\n",
        "```\n",
        "\n",
        "Una volta estratte le probabilità possiamo utilizzare le funzione di `sklearn.metrics`:\n",
        "\n",
        "- `roc_curve`\n",
        "- `roc_auc_score`\n",
        "\n",
        "Di seguito è mostrata la sintassi per utilizzare le due funzioni.\n",
        "\n",
        "---\n",
        "\n",
        "#### `roc_curve`\n",
        "```python\n",
        "# Calcola i valori della curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "```\n",
        "Calcola i valori della Curva ROC (Receiver Operating Characteristic): Tasso di Falsi Positivi (FPR), Tasso di Veri Positivi (TPR) e soglie.\n",
        "\n",
        "---\n",
        "\n",
        "#### `roc_auc_score`\n",
        "```python\n",
        "# Calcola AUC\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "```\n",
        "Calcola l'Area Under the Curve (AUC) per la ROC, quantificando la capacità del modello di distinguere tra classi positive e negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5V-AHBf2IDl"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Estrarre le probabilità dal modello di regressione logistica\n",
        "# ATTENZIONE: Per il calcolo della ROC curve ci servono le probabilità della classe positiva.\n",
        "\n",
        "# svolgimento...\n",
        "y_pred_proba_test= model.predict_proba(X_test)[:,1] #slicing per prendere la classe positiva\n",
        "y_pred_proba_val= model.predict_proba(X_val)[:,1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRoFu2JG2IDm"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Allenare l' SVM con il parametro probability=True ed estrarre le probabilità\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "\n",
        "model = SVC(kernel='linear', C=0.01, probability=True)\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GYpzY4e2IDm"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Calcolare le curve ROC e AUC per entrambe le probabilità (logistic e SVM)\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# svolgimento...\n",
        "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_proba_test)\n",
        "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_pred_proba_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIQ8DDUc2IDm"
      },
      "outputs": [],
      "source": [
        "# Step 4 - Disegnare le curve ROC per entrambe le probabilità (logistic e SVM)\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, auc):\n",
        "    \"\"\"\n",
        "    Disegna la curva ROC e stampa il valore AUC.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    fpr : array-like\n",
        "        Tasso di falsi positivi (False Positive Rate).\n",
        "    tpr : array-like\n",
        "        Tasso di veri positivi (True Positive Rate).\n",
        "    auc : float\n",
        "        Area sotto la curva (AUC).\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.4f}')\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2)  # Linea di non discriminazione\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Stampa il valore AUC\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# svolgimento...\n",
        "auc_test=roc_auc_score(y_test, y_pred_proba_test)\n",
        "auc_val=roc_auc_score(y_val, y_pred_proba_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOZ0iuD12IDm"
      },
      "source": [
        "# **Esercizio 4: Classificazione multi classe**\n",
        "\n",
        "Se finora abbiamo lavorato soltanto con classificazione binaria, adesso addestriamo nuovamente i classificatori visti sopra, ma nella situazione in cui abbiamo più classi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASyKgwlq2IDm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
        "X, y = np.array(mnist.data), np.array(mnist.target.astype(int))\n",
        "\n",
        "# Utilizziamo soltanto il 20% dei campioni del dataset per questioni di praticità\n",
        "n_percent = 0.2\n",
        "\n",
        "# La funzione train_test_split ci assicura che i dati che rimuoviamo siano bilanciati.\n",
        "# In questo modo non alteriamo la distribuzione delle classi.\n",
        "X, _, y, _ = train_test_split(\n",
        "    X, y, train_size=n_percent, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X, y = shuffle(X, y)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YKS6WZj2IDn"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Dividiamo il dataset in train, validation e test e standardizziamo.\n",
        "train_fraction = 0.6\n",
        "validation_fraction = 0.2\n",
        "test_fraction = 0.2\n",
        "\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "dati_completi = np.c_[X, y] #concateniamo dati e target per avere un'unica matrice\n",
        "\n",
        "\n",
        "\n",
        "shape_total = dati_completi.shape[0]\n",
        "shape_train = int(shape_total * train_fraction)\n",
        "shape_val = int(shape_total * validation_fraction)\n",
        "shape_test = shape_total - shape_train - shape_val\n",
        "\n",
        "train_set = dati_completi[:shape_train]\n",
        "val_set = dati_completi[shape_train:shape_train + shape_val]\n",
        "test_set = dati_completi[shape_train + shape_val:]\n",
        "\n",
        "X_train, y_train = train_set[:, :-1], train_set[:, -1]\n",
        "X_val, y_val = val_set[:, :-1], val_set[:, -1]\n",
        "X_test, y_test = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "scaler = StandardScaler() #standardizzazione\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(X_train_scaled.shape, y_train.shape)\n",
        "print(X_val_scaled.shape, y_val.shape)\n",
        "print(X_test_scaled.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcN4uXBG2IDn"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Alleniamo il modello di regressione logistica e calcoliamo le predizioni e prestazioni.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# IMPORTANTE:\n",
        "# Quando istanziamo la classe LogisticRegression utilizziamo come parametri\n",
        "# max_iter=200 e solver='lbfgs'.\n",
        "\n",
        "# svolgimento...\n",
        "model = LogisticRegression(max_iter=200, solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "prediction_val=model.predict(X_val_scaled)\n",
        "prediction_test=model.predict(X_test_scaled)\n",
        "correct_val=np.sum(y_val==prediction_val)\n",
        "total_val=len(y_val)\n",
        "accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test=np.sum(y_test==prediction_test)\n",
        "total_test=len(y_test)\n",
        "accuracy_test=correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"Linear regression multi class accuracy: {accuracy_val:4f}\")\n",
        "print(f\"Test accuracy: {accuracy_test:4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nliAchKv2IDn"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Alleniamo il modello di SVM e calcoliamo le predizioni e prestazioni.\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# IMPORTANTE:\n",
        "# Quando istanziamo la classe SVC utilizziamo come parametri C=0.01,\n",
        "# kernel='linear' e decision_function_shape='ovr'.\n",
        "\n",
        "# svolgimento...\n",
        "model = SVC(C=0.01, kernel='linear', decision_function_shape='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "prediction_val=model.predict(X_val_scaled)\n",
        "prediction_test=model.predict(X_test_scaled)\n",
        "correct_val=np.sum(y_val==prediction_val)\n",
        "total_val=len(y_val)\n",
        "accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test=np.sum(y_test==prediction_test)\n",
        "total_test=len(y_test)\n",
        "accuracy_test=correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"SVM linear multi class accuracy: {accuracy_val:4f}\")\n",
        "print(f\"Test accuracy: {accuracy_test:4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljz1jrmo2IDn"
      },
      "source": [
        "# **Esercizio 5: Scrivere una funzione pipeline per l' allenamento di un classificatore**\n",
        "\n",
        "La funzione `pipeline` prende in input il train set, `X_train` e `y_train`, il validation set, `X_val` e `y_val`, e un dizionario `hyperparams` che contiene una configurazione di training.\n",
        "\n",
        "La funzione deve:\n",
        "\n",
        "* Applicare la PCA **se richiesto**.\n",
        "\n",
        "* Standardizzare i dati **a prescindere che sia richiesto o meno**.\n",
        "\n",
        "* Allenare un classificatore. Il dizionario avrà una chiave `classifier`, il cui value può essere:\n",
        "\n",
        "    * `lr` per indicare un modello di **Regressione Logistica**.\n",
        "    * `svm` per indicare un modello **SVM**.\n",
        "\n",
        "* Effettuare le predizioni e utilizzarle per calcolare l' accuracy del classificatore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN5CAQRH2IDo"
      },
      "outputs": [],
      "source": [
        "# IMPORTANTE: Eseguire questa cella prima di procedere\n",
        "\n",
        "def plot_confusion_matrix_multiclass(cm):\n",
        "    \"\"\"\n",
        "    Visualizza una matrice di confusione come heatmap.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    cm : numpy.ndarray\n",
        "        La matrice di confusione da visualizzare\n",
        "    \"\"\"\n",
        "    # Calcola dinamicamente le etichette delle classi\n",
        "    class_labels = [f\"Class {i}\" for i in range(cm.shape[0])]\n",
        "\n",
        "    # Visualizza la heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwllI0sc2IDo"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def pipeline(X_train, y_train, X_val, y_val, hyperparams):\n",
        "\n",
        "    if hyperparams['use_pca']:\n",
        "\n",
        "        # Implementare codice per la PCA\n",
        "        pca = PCA(n_components=0.95)\n",
        "        X_train_pca = pca.fit_transform(X_train)\n",
        "        X_val_pca = pca.transform(X_val)\n",
        "\n",
        "    # Implementare codice per la standardizzazione\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    if hyperparams['classifier'] == 'lr':\n",
        "        # Implementare codice per Regressione Lineare\n",
        "        model = LogisticRegression(max_iter=200, solver='lbfgs')\n",
        "        model.fit(X_train, y_train)\n",
        "        prediction_val=model.predict(X_val_scaled)\n",
        "\n",
        "    elif hyperparams['classifier'] == 'svm':\n",
        "        # Implementare codice per SVM\n",
        "        model = SVC(C=0.01, kernel='linear', decision_function_shape='ovr')\n",
        "        model.fit(X_train, y_train)\n",
        "        prediction_val=model.predict(X_val_scaled)\n",
        "\n",
        "    # Effettuare predizioni\n",
        "    prediction_val=model.predict(X_val_scaled)\n",
        "    prediction_test=model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "    # Calcolare e stampare accuracy sul validation set\n",
        "    correct_val=np.sum(y_val==prediction_val)\n",
        "    total_val=len(y_val)\n",
        "    accuracy_val=correct_val/total_val if total_val>0 else 0\n",
        "    print(f\"Accuracy: {accuracy_val:4f}\")\n",
        "\n",
        "\n",
        "    # Calcolare la matrice di confusione\n",
        "    cm = confusion_matrix(y_val, prediction_val)\n",
        "    # Visualizzare la matrice di confusione\n",
        "    plot_confusion_matrix_multiclass(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-PfFhuT2IDo"
      },
      "outputs": [],
      "source": [
        "# Provare la funzione pipeline su tutte le configurazioni presenti qui di seguito\n",
        "\n",
        "hyperparams_1 = {\n",
        "    'use_pca': False,\n",
        "    'classifier': 'svm',\n",
        "}\n",
        "\n",
        "\n",
        "hyperparams_2 = {\n",
        "    'use_pca': True,\n",
        "    'classifier': 'svm',\n",
        "}\n",
        "\n",
        "hyperparams_3 = {\n",
        "    'use_pca': False,\n",
        "    'classifier': 'lr',\n",
        "}\n",
        "\n",
        "hyperparams_4 = {\n",
        "    'use_pca': True,\n",
        "    'classifier': 'lr',\n",
        "}\n",
        "\n",
        "# svolgimento...\n",
        "pipeline(X_train, y_train, X_val, y_val, hyperparams_1)\n",
        "pipeline(X_train, y_train, X_val, y_val, hyperparams_2)\n",
        "pipeline(X_train, y_train, X_val, y_val, hyperparams_3)\n",
        "pipeline(X_train, y_train, X_val, y_val, hyperparams_4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsAThQ662IDo"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}